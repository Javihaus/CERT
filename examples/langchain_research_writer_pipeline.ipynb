{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Multi-Agent Pipeline: Research → Writer → Editor\n",
    "\n",
    "This notebook demonstrates a **real production multi-agent pipeline** using LangChain with CERT SDK instrumentation.\n",
    "\n",
    "## Pipeline Architecture\n",
    "\n",
    "```\n",
    "User Query → Researcher Agent → Writer Agent → Editor Agent → Final Output\n",
    "```\n",
    "\n",
    "**Agents:**\n",
    "1. **Researcher**: Gathers information and key points\n",
    "2. **Writer**: Creates initial content draft\n",
    "3. **Editor**: Refines and polishes the final output\n",
    "\n",
    "**CERT Metrics Measured:**\n",
    "- Individual agent quality scores\n",
    "- Coordination effect (γ) - how agents improve each other\n",
    "- Pipeline health score\n",
    "- Execution timing and observability\n",
    "\n",
    "**Estimated time:** 3-5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install cert-sdk langchain langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import cert\n",
    "from cert.integrations.langchain import CERTLangChain\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize CERT Provider and Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CERT provider for baseline comparison\n",
    "cert_provider = cert.create_provider(\n",
    "    api_key=api_key,\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Get validated baseline\n",
    "baseline = cert.ModelRegistry.get_model(\"gpt-4o\")\n",
    "\n",
    "print(f\"✓ Using {baseline.model_id}\")\n",
    "print(f\"  Baseline: C={baseline.consistency:.3f}, μ={baseline.mean_performance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CERT LangChain integration\n",
    "cert_integration = CERTLangChain(\n",
    "    provider=cert_provider,\n",
    "    baseline=baseline,\n",
    "    verbose=True,  # Print execution details\n",
    ")\n",
    "\n",
    "print(\"✓ CERT LangChain integration initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Three Agents\n",
    "\n",
    "We'll create three specialized agents with distinct roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(\"✓ LangChain LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Researcher\n",
    "researcher_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a research expert. Analyze the user's question and provide key research points, facts, and insights. Be thorough and factual.\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "class ResearcherAgent:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def invoke(self, input_data):\n",
    "        messages = input_data.get(\"messages\", [])\n",
    "        user_input = messages[-1] if messages else input_data.get(\"input\", \"\")\n",
    "        \n",
    "        if isinstance(user_input, dict):\n",
    "            user_input = user_input.get(\"content\", str(user_input))\n",
    "        elif hasattr(user_input, \"content\"):\n",
    "            user_input = user_input.content\n",
    "        else:\n",
    "            user_input = str(user_input)\n",
    "        \n",
    "        formatted = self.prompt.format_messages(input=user_input)\n",
    "        response = self.llm.invoke(formatted)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": user_input},\n",
    "                {\"role\": \"assistant\", \"content\": response.content}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "researcher = ResearcherAgent(llm, researcher_prompt)\n",
    "print(\"✓ Researcher agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Writer\n",
    "writer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a professional writer. Take the research points provided and create a well-structured, engaging article. Focus on clarity and flow.\"),\n",
    "    (\"human\", \"Research points: {input}\"),\n",
    "])\n",
    "\n",
    "class WriterAgent:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def invoke(self, input_data):\n",
    "        messages = input_data.get(\"messages\", [])\n",
    "        research_content = messages[-1].get(\"content\", \"\") if messages else \"\"\n",
    "        \n",
    "        formatted = self.prompt.format_messages(input=research_content)\n",
    "        response = self.llm.invoke(formatted)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": research_content},\n",
    "                {\"role\": \"assistant\", \"content\": response.content}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "writer = WriterAgent(llm, writer_prompt)\n",
    "print(\"✓ Writer agent created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Editor\n",
    "editor_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert editor. Review the draft article and improve it by fixing grammar, enhancing clarity, and ensuring professional quality. Keep the core content but polish it.\"),\n",
    "    (\"human\", \"Draft to edit: {input}\"),\n",
    "])\n",
    "\n",
    "class EditorAgent:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "    \n",
    "    def invoke(self, input_data):\n",
    "        messages = input_data.get(\"messages\", [])\n",
    "        draft_content = messages[-1].get(\"content\", \"\") if messages else \"\"\n",
    "        \n",
    "        formatted = self.prompt.format_messages(input=draft_content)\n",
    "        response = self.llm.invoke(formatted)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": draft_content},\n",
    "                {\"role\": \"assistant\", \"content\": response.content}\n",
    "            ]\n",
    "        }\n",
    "\n",
    "editor = EditorAgent(llm, editor_prompt)\n",
    "print(\"✓ Editor agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instrumented Pipeline\n",
    "\n",
    "Now we'll wrap each agent with CERT instrumentation and create the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap agents with CERT instrumentation\n",
    "instrumented_researcher = cert_integration.wrap_agent(\n",
    "    agent=researcher,\n",
    "    agent_id=\"researcher\",\n",
    "    agent_name=\"Research Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "instrumented_writer = cert_integration.wrap_agent(\n",
    "    agent=writer,\n",
    "    agent_id=\"writer\",\n",
    "    agent_name=\"Writer Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "instrumented_editor = cert_integration.wrap_agent(\n",
    "    agent=editor,\n",
    "    agent_id=\"editor\",\n",
    "    agent_name=\"Editor Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "print(\"✓ All agents instrumented with CERT metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline using CERT's helper\n",
    "pipeline = cert_integration.create_multi_agent_pipeline([\n",
    "    {\"agent\": researcher, \"agent_id\": \"researcher\", \"agent_name\": \"Research Agent\"},\n",
    "    {\"agent\": writer, \"agent_id\": \"writer\", \"agent_name\": \"Writer Agent\"},\n",
    "    {\"agent\": editor, \"agent_id\": \"editor\", \"agent_name\": \"Editor Agent\"},\n",
    "])\n",
    "\n",
    "print(\"✓ Multi-agent pipeline created\")\n",
    "print(\"\\n  Pipeline: Research → Write → Edit → Final Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Let's test the pipeline with a real query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user query\n",
    "user_query = \"Explain the key factors in building successful multi-agent AI systems for production.\"\n",
    "\n",
    "print(f\"User Query: {user_query}\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Executing Pipeline...\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "result = pipeline({\"messages\": [{\"role\": \"user\", \"content\": user_query}]})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Pipeline Execution Complete\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final output\n",
    "final_output = result[\"messages\"][-1][\"content\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\"*70)\n",
    "print(final_output)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View CERT Metrics\n",
    "\n",
    "Now let's see the CERT metrics collected during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive metrics\n",
    "cert_integration.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the Results\n",
    "\n",
    "### Quality Scores\n",
    "- Each agent's output is scored for semantic relevance, linguistic coherence, and content density\n",
    "- Higher scores (closer to 1.0) indicate better quality\n",
    "\n",
    "### Coordination Effect (γ)\n",
    "- **γ > 1.0**: Agents are coordinating well - each agent improves on the previous\n",
    "- **γ = 1.0**: No coordination benefit\n",
    "- **γ < 1.0**: Agents may be interfering with each other\n",
    "\n",
    "### Pipeline Health\n",
    "- **H > 0.8**: Production ready - deploy with confidence\n",
    "- **0.6 < H < 0.8**: Acceptable - deploy with monitoring\n",
    "- **H < 0.6**: Needs investigation before production\n",
    "\n",
    "### Execution Timing\n",
    "- Shows duration for each agent\n",
    "- Helps identify bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metrics Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access metrics as dictionary\n",
    "metrics_dict = cert_integration.get_metrics_summary()\n",
    "\n",
    "print(\"Metrics Summary:\")\n",
    "for key, value in metrics_dict.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Test the pipeline with different types of queries to see how coordination effects vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries to try\n",
    "example_queries = [\n",
    "    \"What are the challenges in deploying LLM agents to production?\",\n",
    "    \"Explain how to measure AI agent performance and reliability.\",\n",
    "    \"Compare different multi-agent frameworks for enterprise applications.\",\n",
    "]\n",
    "\n",
    "print(\"Try these queries:\")\n",
    "for i, query in enumerate(example_queries, 1):\n",
    "    print(f\"  {i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Deployment\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Use CERT metrics** to validate your pipeline before production\n",
    "2. **Monitor coordination effect** - if γ drops, investigate agent interactions\n",
    "3. **Track health score** - set alerts if it falls below your threshold\n",
    "4. **Measure consistently** - run CERT measurements regularly to detect drift\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try the CrewAI integration: `examples/crewai_pipeline.ipynb`\n",
    "- Learn about custom baselines: `examples/advanced_usage.ipynb`\n",
    "- Explore the full API: See README.md for documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
