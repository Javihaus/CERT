{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Multi-Agent Pipeline: Research → Writer → Editor\n",
    "\n",
    "This notebook demonstrates a **real production multi-agent pipeline** using LangChain with CERT SDK instrumentation.\n",
    "\n",
    "## Pipeline Architecture\n",
    "\n",
    "```\n",
    "User Query → Researcher Agent → Writer Agent → Editor Agent → Final Output\n",
    "```\n",
    "\n",
    "**Agents:**\n",
    "1. **Researcher**: Gathers information and key points\n",
    "2. **Writer**: Creates initial content draft\n",
    "3. **Editor**: Refines and polishes the final output\n",
    "\n",
    "**CERT Metrics Measured:**\n",
    "- Individual agent quality scores\n",
    "- Context propagation effect (γ) - performance changes from accumulated context\n",
    "- Pipeline health score\n",
    "- Execution timing and observability\n",
    "\n",
    "**Estimated time:** 3-5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Option 1: From PyPI (when available)\n",
    "# !pip install cert-sdk langchain langchain-openai\n",
    "\n",
    "# Option 2: Directly from GitHub repository (development version)\n",
    "# !pip install git+https://github.com/Javihaus/CERT.git langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import cert\n",
    "from cert.integrations.langchain import CERTLangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key = getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize CERT Provider and Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CERT provider for baseline comparison\n",
    "cert_provider = cert.create_provider(\n",
    "    api_key=api_key,\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "# Get validated baseline\n",
    "baseline = cert.ModelRegistry.get_model(\"gpt-4o\")\n",
    "\n",
    "print(f\"✓ Using {baseline.model_id}\")\n",
    "print(f\"  Baseline: C={baseline.consistency:.3f}, μ={baseline.mean_performance:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CERT LangChain integration\n",
    "cert_integration = CERTLangChain(\n",
    "    provider=cert_provider,\n",
    "    baseline=baseline,\n",
    "    verbose=True,  # Print execution details\n",
    ")\n",
    "\n",
    "print(\"✓ CERT LangChain integration initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Three Agents\n",
    "\n",
    "We'll create three specialized agents using **LangChain's LCEL (LangChain Expression Language)** - the simplest possible approach!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(\n",
    "    api_key=api_key,\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(\"✓ LangChain LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Researcher (using LCEL: prompt | llm)\n",
    "researcher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a research expert. Analyze the user's question and provide key research points, facts, and insights. Be thorough and factual.\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "researcher = researcher_prompt | llm\n",
    "print(\"✓ Researcher agent created (LCEL chain: prompt | llm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: Writer (using LCEL: prompt | llm)\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a professional writer. Take the research points provided and create a well-structured, engaging article. Focus on clarity and flow.\",\n",
    "        ),\n",
    "        (\"human\", \"Research points:\\n{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | llm\n",
    "print(\"✓ Writer agent created (LCEL chain: prompt | llm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Editor (using LCEL: prompt | llm)\n",
    "editor_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert editor. Review the draft article and improve it by fixing grammar, enhancing clarity, and ensuring professional quality. Keep the core content but polish it.\",\n",
    "        ),\n",
    "        (\"human\", \"Draft to edit:\\n{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "editor = editor_prompt | llm\n",
    "print(\"✓ Editor agent created (LCEL chain: prompt | llm)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Instrumented Agents\n",
    "\n",
    "Wrap each LCEL chain with CERT instrumentation. CERT now natively supports LCEL chains!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the LCEL chains with CERT instrumentation\n",
    "instrumented_researcher = cert_integration.wrap_agent(\n",
    "    agent=researcher,\n",
    "    agent_id=\"researcher\",\n",
    "    agent_name=\"Research Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "instrumented_writer = cert_integration.wrap_agent(\n",
    "    agent=writer,\n",
    "    agent_id=\"writer\",\n",
    "    agent_name=\"Writer Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "instrumented_editor = cert_integration.wrap_agent(\n",
    "    agent=editor,\n",
    "    agent_id=\"editor\",\n",
    "    agent_name=\"Editor Agent\",\n",
    "    calculate_quality=True,\n",
    ")\n",
    "\n",
    "print(\"✓ All agents wrapped with CERT instrumentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Execute the agents sequentially, with each agent processing the output of the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the user query\n",
    "user_query = (\n",
    "    \"Explain the key factors in building successful multi-model LLM systems for production.\"\n",
    ")\n",
    "\n",
    "print(f\"User Query: {user_query}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Executing Pipeline...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset metrics\n",
    "cert_integration.reset_metrics()\n",
    "\n",
    "# Execute pipeline: each agent processes the output of the previous one\n",
    "research_output = instrumented_researcher.invoke({\"input\": user_query})\n",
    "draft_output = instrumented_writer.invoke({\"input\": research_output.content})\n",
    "final_output = instrumented_editor.invoke({\"input\": draft_output.content})\n",
    "\n",
    "# Calculate CERT metrics\n",
    "cert_integration.calculate_coordination_effect()\n",
    "cert_integration.calculate_pipeline_health()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Pipeline Execution Complete\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final output\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\" * 70)\n",
    "print(final_output.content)\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View CERT Metrics\n",
    "\n",
    "Now let's see the CERT metrics collected during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive metrics\n",
    "cert_integration.print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the Results\n",
    "\n",
    "### Quality Scores\n",
    "- Each agent's output is scored for semantic relevance, linguistic coherence, and content density\n",
    "- Higher scores (closer to 1.0) indicate better quality\n",
    "\n",
    "### Context Propagation Effect (γ)\n",
    "**What it measures:**\n",
    "- Performance changes when models process accumulated context\n",
    "- How attention mechanisms handle extended context in sequential processing\n",
    "\n",
    "**What it does NOT measure:**\n",
    "- ❌ Agent coordination, collaboration, or planning\n",
    "- ❌ Intelligence or reasoning capabilities\n",
    "- ❌ WHY context helps (black box measurement)\n",
    "\n",
    "**Interpretation:**\n",
    "- **γ > 1.0**: Sequential context accumulation improves performance\n",
    "- **γ = 1.0**: No benefit from accumulated context\n",
    "- **γ < 1.0**: Context accumulation degrades performance\n",
    "\n",
    "### Pipeline Health\n",
    "- **H > 0.8**: Production ready - deploy with confidence\n",
    "- **0.6 < H < 0.8**: Acceptable - deploy with monitoring\n",
    "- **H < 0.6**: Needs investigation before production\n",
    "\n",
    "### Execution Timing\n",
    "- Shows duration for each agent\n",
    "- Helps identify bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metrics Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access metrics as dictionary\n",
    "metrics_dict = cert_integration.get_metrics_summary()\n",
    "\n",
    "print(\"Metrics Summary:\")\n",
    "for key, value in metrics_dict.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Test the pipeline with different types of queries to see how context propagation effects vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries to try\n",
    "example_queries = [\n",
    "    \"What are the challenges in deploying LLM agents to production?\",\n",
    "    \"Explain how to measure AI agent performance and reliability.\",\n",
    "    \"Compare different multi-model frameworks for enterprise applications.\",\n",
    "]\n",
    "\n",
    "print(\"Try these queries:\")\n",
    "for i, query in enumerate(example_queries, 1):\n",
    "    print(f\"  {i}. {query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Deployment\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Use CERT metrics** to validate your pipeline before production\n",
    "2. **Monitor context propagation effect (γ)** - if γ drops, investigate sequential processing behavior\n",
    "3. **Track health score** - set alerts if it falls below your threshold\n",
    "4. **Measure consistently** - run CERT measurements regularly to detect drift\n",
    "\n",
    "### What CERT Measures:\n",
    "\n",
    "✅ **Engineering Characterization:**\n",
    "- Statistical behavior of sequential LLM processing\n",
    "- Performance changes from context accumulation\n",
    "- Attention mechanism effects (black box measurement)\n",
    "- Operational metrics for deployment decisions\n",
    "\n",
    "❌ **What CERT Does NOT Measure:**\n",
    "- Agent coordination or collaboration\n",
    "- Intelligence or reasoning capabilities\n",
    "- WHY models improve with context\n",
    "\n",
    "This is **engineering instrumentation**, not coordination science.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try the CrewAI integration: `examples/crewai_pipeline.ipynb`\n",
    "- Learn about custom baselines: `examples/advanced_usage.py`\n",
    "- Explore the full API: See README.md for documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}